{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "548968a4",
   "metadata": {},
   "source": [
    "Step1 : 데이터 수집하기\n",
    "웹캠에서 얼굴 부분만 검출하여 사진 100장 찍어 폴더에 저장하기\n",
    "\n",
    "1) cv2.CascadeClassifier() 객체 선언하기\n",
    "2) cv2.VideoCapture(0) 객체 선언하기\n",
    "3) 웹캠이 열려있으면\n",
    "frame 을 읽어서\n",
    "회색조로 변경\n",
    "detectMultiScale() 사용하여 얼굴 감지하기\n",
    "감지된 얼굴에 대해 사이즈  줄여 지정한 폴더에 구분자를 붙여 이미지로 저장하기(cv2.imwrite())\n",
    "화면에는 카운트 숫자 표기하기\n",
    "'q'로 종료하거나 count 가 100일때 종료하기\n",
    "\n",
    "Step2 : 모델 학습하기\n",
    "저장된 얼굴 이미지를 읽어서 모델 학습하기\n",
    "1) 저장된 폴더에서 이미지를 읽어(cv2.imread() ) 회색조로 저장하기\n",
    "2) 100장의 이미지를 리스트에 학습할 데이터(Training_Data) 와 Labels을 append 하여 각각 저장하기\n",
    "3) 모델 생성하기 : model = cv2.face.LBPHFaceRecognizer_create()\n",
    "4) 모델 학습하기 : model.train(Training_Data, Labels)\n",
    "5) 훈련된 모델 파일로 저장하기 :model.write('face_model.yml')\n",
    "\n",
    "Step3 : 얼굴 인식하기\n",
    "분류기를 사용하여 웹캠에 비친 얼굴 중 학습한 사용자 인식하기\n",
    "1) cv2.CascadeClassifier() 객체 선언하기\n",
    "2) cv2.VideoCapture(0) 객체 선언하기\n",
    "3) 웹캠이 열려있으면\n",
    "frame 을 읽어서\n",
    "회색조로 변경\n",
    "detectMultiScale() 사용하여 얼굴 감지하기\n",
    "얼굴이 검출된 경우\n",
    "회색조로 변경하고\n",
    "모델 예측하기 : model.predict()\n",
    "예측 결과 신뢰도로가 75 이상인경우 화면에 \"ACCESS GRANTED\"\n",
    "        아니면 \"ACCESS DENIED\"\n",
    "'q'로 종료"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49c88edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2              # OpenCV 라이브러리 가져오기\n",
    "import numpy as np      # Numpy 라이브러리 가져오기\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "Training_Data = []\n",
    "Labels = []\n",
    "\n",
    "for i in range(100):        \n",
    "    x = cv2.imread(\"./data_CCS/image\"  + str(i) + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if x is not None:\n",
    "        Training_Data.append(x)\n",
    "        Labels.append(1)\n",
    "    \n",
    "for i in range(130):\n",
    "    x = cv2.imread(\"./data_CJH/saved_image\"  + format(i, '03') + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if x is not None:\n",
    "        Training_Data.append(x)\n",
    "        Labels.append(2)\n",
    "    \n",
    "for i in range(100):    \n",
    "    x = cv2.imread(\"./data_JHW/\"  + str(i) + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if x is not None:\n",
    "        Training_Data.append(x)\n",
    "        Labels.append(3)\n",
    "    \n",
    "for i in range(100):\n",
    "    x = cv2.imread(\"./data_KJD/image_\"  + str(i) + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if x is not None:\n",
    "        Training_Data.append(x)\n",
    "        Labels.append(4)        \n",
    "    \n",
    "for i in range(100):\n",
    "    x = cv2.imread(\"./data_KOJ/img_\"  + format(i, '03') + \".jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    if x is not None:\n",
    "        Training_Data.append(x)\n",
    "        Labels.append(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d2bac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def matdraw(img):\n",
    "    plt.axis('off') # 창에있는 x축 y축 제거\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.show()\n",
    "    \n",
    "# 다수 mat 그리기 함수\n",
    "def matsdraw(imgs, row, col):\n",
    "    for idx in range(len(imgs)):\n",
    "        plt.subplot(row, col, idx + 1)\n",
    "        plt.axis('off') # 창에있는 x축 y축 제거\n",
    "        plt.imshow(cv2.cvtColor(imgs[idx], cv2.COLOR_BGR2RGB))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1062519",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    matdraw(Training_Data[i * 50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "836e539a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'list'>\n",
      "459\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{1: 59, 2: 100, 3: 100, 4: 100, 5: 100}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(Training_Data))\n",
    "print(type(Training_Data[i]))\n",
    "print(type(Labels))\n",
    "print(len(Labels))\n",
    "\n",
    "unique, counts = np.unique(Labels, return_counts = True)\n",
    "uniq_cnt_dict = dict(zip(unique, counts))\n",
    "\n",
    "uniq_cnt_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dea720fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "model.train(Training_Data, np.array(Labels))\n",
    "model.write('team_face_model.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abb3b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2              # OpenCV 라이브러리 가져오기\n",
    "import numpy as np      # Numpy 라이브러리 가져오기\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# cv2.CascadeClassifier() \n",
    "# face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# 전통적인 cv로 만든 classifier임\n",
    "face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "camera = cv2.VideoCapture(0) #' 첫 번째' 카메라(웹캠)로 VideoCapture 객체 생성  \n",
    "\n",
    "model=cv2.face.LBPHFaceRecognizer_create();\n",
    "model.read(\"team_face_model.yml\")\n",
    "confidence = 0\n",
    "\n",
    "while(True):\n",
    "    ret, frame = camera.read()                              # 프레임 단위로 캡처    \n",
    "    frame = cv2.resize(frame, (800, 600))\n",
    "    faces = face_classifier.detectMultiScale(frame, 1.3, 5)\n",
    "    \n",
    "    # 화면에 비친 인원 모두에게 사각형 표시\n",
    "    # 접근 허가라고 출력\n",
    "    if(len(faces) > 0): \n",
    "        for (x, y, w, h) in faces:\n",
    "            crop = frame[y:y+h, x:x+w].copy()   \n",
    "            crop = cv2.cvtColor(crop, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            result = model.predict(crop)            \n",
    "        \n",
    "            confidence = int(100 * (1 - (result[1] / 300)))\n",
    "            \n",
    "            if (result[1] < 50):            \n",
    "                if((result[0] == 1) & (confidence > 75)):\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 100, 100), 5)\n",
    "                    cv2.putText(frame, \"Hi! CCS\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 100, 100),3)\n",
    "                    \n",
    "                elif((result[0] == 2) & (confidence > 75)):\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 100, 100), 5)\n",
    "                    cv2.putText(frame, \"Hi! CJH\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 100, 100),3)\n",
    "                    \n",
    "                elif((result[0] == 3) & (confidence > 75)):\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 100, 100), 5)\n",
    "                    cv2.putText(frame, \"Hi! JHW\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 100, 100),3)\n",
    "                    \n",
    "                elif((result[0] == 4) & (confidence > 75)):\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 100, 100), 5)\n",
    "                    cv2.putText(frame, \"Hi! KJD\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 100, 100),2)\n",
    "                    \n",
    "                elif((result[0] == 5) & (confidence > 75)):\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 100, 100), 5)\n",
    "                    cv2.putText(frame, \"Hi! KOJ\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255, 100, 100),3)\n",
    "                else:\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), (100, 100, 255), 5)\n",
    "                    cv2.putText(frame, \"Who...?\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (100, 100, 255),3)\n",
    "            \n",
    "            else:\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (100, 255, 255), 5)\n",
    "                cv2.putText(frame, \"Not sure\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (100, 255, 255),3)\n",
    "            \n",
    "\n",
    "    cv2.imshow('Press q to Exit',frame)              # 프레임 표시\n",
    "    \n",
    "    if (cv2.waitKey(1) & 0xFF == ord('q')):  # 스페이스바가 감지되면 중지\n",
    "        break\n",
    "\n",
    "camera.release()                           # 스페이스바가 감지된 후 창을 종료\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
