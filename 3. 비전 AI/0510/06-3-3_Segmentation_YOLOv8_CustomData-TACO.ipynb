{"cells":[{"cell_type":"markdown","metadata":{"id":"vA7qOmKF3M03"},"source":["## **Custom Dataset로 Yolov8 재학습하여 객체 감지 예측하기**\n","\n","**< 진행 절차 >**\n","1. Data 준비하기 : Custom Dataset Dataset으로 Yolov8 재학습(Fine Tuning)하는 경우에는 Image / Annotation 으로 이루어진 Dataset 준비\n","    - Roboflow에서 제공하는 Training Dataset을 이용하거나 Labeling Tool 을 이용하여 개발자가 직접 Labeling 시킨 Image / Annotation으로 이루어진 Training Dataset을 구축해야함\n","    - Custom Dataset 구축시 이미지 데이터와 정답데이터는 확장자를 제외한 파일 이름은 동일해야하며 Yolov8에서 annotation 파일 즉 정답 파일의 확장자는 반드시 .txt 여야 함         \n","\n","- 1) Roboflow 에서 Aquarium Dataset (custom data) 다운로드\n","    - Colab 으로 데이터셋 업로드 : Roboflow(https://public.roboflow.com/)에서 제공하는 Dataset 로드하기\n","- 2) yaml 파일 설정** (데이터셋 위치 알려주는 config file)\n","    - 2-1) roboflow 에서 제공되는 data.yaml 파일 확인\n","    - 2-2) custom data에 대한 yaml 파일 만들기\n","    Yolov8으로 Custom Data를 학습하기 위해서는 YAML 파일이 반드시 필요. YAML 파일에는 다음 정보를 포함해야함\n","        - 이미지와 정답이 저장되어 있는 디렉토리 정보\n","        - 인식하고 싶은 클래스 종류와 대응대는 각각의 이름\n","        - 형식 : 클래스번호 | x의 center 좌표|y의 center좌표| 너비 |높이  \n","            - 전체 이미지의 width 와 height 값으로 나눈 비율값임\n","\n","2. ultralytics 패키지 설치하기\n","```python\n","pip install ultralytics\n","```\n","3. 모델 객체 선언하고 학습하기\n","```python\n","from ultralytics import YOLO\n","model = YOLO('yolov8n-seg.pt')  #  model = YOLO('yolov8n-seg.pt')\n","model.train(data='mydata.yaml', epochs=10)\n","```\n","4. 객체 검출하기\n","```python\n","results = model.predict(source='/content/test/')\n","```\n","5. 결과 확인하기\n","6. 결과 다운로드하기\n","7. 학습된 모델 내보내기\n","8. 웹캠에서 모델 사용하여 객체 검출하기"]},{"cell_type":"markdown","metadata":{"id":"jy2kdA9zRfWq"},"source":["## **1. 데이터 준비하기(Custom Data 구축)**\n","- Roboflow에서 제공하는 Training Dataset을 이용\n","\n","### 1) Roboflow 에서 Aquarium Dataset (custom data) 다운로드\n","- Public Dataset : https://public.roboflow.com/object-detection/aquarium/2\n","- Download Dataset > Export - Select Format : Yolov8, show download code 선택 후  continue 버튼 클릭 > Your Download Code - Raw URL 탭에서 주조 복사하기"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3539,"status":"ok","timestamp":1715314342871,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"ts3XxoBRaGxa","outputId":"b0450a9c-ba94-40c8-f735-394131b11f87"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-05-10 04:12:17--  https://universe.roboflow.com/ds/xXC7BINMyr?key=mUADdMGHFn\n","Resolving universe.roboflow.com (universe.roboflow.com)... 151.101.1.195, 151.101.65.195, 2620:0:890::100\n","Connecting to universe.roboflow.com (universe.roboflow.com)|151.101.1.195|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://storage.googleapis.com/roboflow-platform-regional-exports/arRagmpkRzqLfrKDYQ18/C81DPW344cTH8hw4toez/16/yolov8.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20240510%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240510T041218Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=1739d27673ad7bb7b86dc16b41efe3e892f1ee953a78d5b42b5c29577c0a8656a0d9bd8c49c75000239b513857f29061b5e5d6d7407aed6c40e5214be3c1a3a086b99bede70f6f6c175c42c31ee32163e507b5c677d60483553f924457e05306224c444a5828344cdea6a364e24f93386b169822c76b02d7d5c4e6c34d09407eda00e757e8b24da207185d73752b2c5fdf8370f151b0fbbf2afb65903d262bd8819d269f49f8b4d1d2aca2919909e891cbfc2465229bd8840adc9c7ef47ddb915f79cba60a8a5a48a36afd2505c95a10e27b41a0d64582d451534f702be21ad342dc8d79d0a36fa39fa1c458e8e36506bbf70332494b52852ce81b77cd555f68 [following]\n","--2024-05-10 04:12:18--  https://storage.googleapis.com/roboflow-platform-regional-exports/arRagmpkRzqLfrKDYQ18/C81DPW344cTH8hw4toez/16/yolov8.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=481589474394-compute%40developer.gserviceaccount.com%2F20240510%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240510T041218Z&X-Goog-Expires=900&X-Goog-SignedHeaders=host&X-Goog-Signature=1739d27673ad7bb7b86dc16b41efe3e892f1ee953a78d5b42b5c29577c0a8656a0d9bd8c49c75000239b513857f29061b5e5d6d7407aed6c40e5214be3c1a3a086b99bede70f6f6c175c42c31ee32163e507b5c677d60483553f924457e05306224c444a5828344cdea6a364e24f93386b169822c76b02d7d5c4e6c34d09407eda00e757e8b24da207185d73752b2c5fdf8370f151b0fbbf2afb65903d262bd8819d269f49f8b4d1d2aca2919909e891cbfc2465229bd8840adc9c7ef47ddb915f79cba60a8a5a48a36afd2505c95a10e27b41a0d64582d451534f702be21ad342dc8d79d0a36fa39fa1c458e8e36506bbf70332494b52852ce81b77cd555f68\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.26.207, 172.217.193.207, 172.217.204.207, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.26.207|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 340367252 (325M) [application/zip]\n","Saving to: ‘TACO_Data1.zip’\n","\n","TACO_Data1.zip      100%[===================>] 324.60M  98.6MB/s    in 3.5s    \n","\n","2024-05-10 04:12:21 (92.7 MB/s) - ‘TACO_Data1.zip’ saved [340367252/340367252]\n","\n"]}],"source":["# Roboflow 에서 직접 다운로드\n","\n","!wget -O TACO_Data1.zip https://universe.roboflow.com/ds/xXC7BINMyr?key=mUADdMGHFn"]},{"cell_type":"markdown","metadata":{"id":"Cl0qVp8_3XzI"},"source":["- 압축파일 해제하기"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"CnJg5zyZaT-t","executionInfo":{"status":"ok","timestamp":1715314345508,"user_tz":-540,"elapsed":2640,"user":{"displayName":"가온새나","userId":"00832727552783796679"}}},"outputs":[],"source":["import zipfile\n","\n","with zipfile.ZipFile('/content/TACO_Data1.zip') as target_file:\n","    target_file.extractall('/content/TACO_Data/')"]},{"cell_type":"markdown","metadata":{"id":"C4l2FIiJE1s7"},"source":["## **2) yaml 파일 설정** (데이터셋 위치 알려주는 config file)\n","- YAML : 데이터 표현 양식의 한 종류\n","- 기본적으로 들여쓰기(indent)를 원칙으로하며 데이터는 Map(key-value)형식으로 작성\n","\n","### 2-1) roboflow 에서 제공되는 data.yaml 파일 확인"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715314345509,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"Wmum2kbAj-h3","outputId":"95f06b19-6240-4a9c-b63e-a02259fc8365"},"outputs":[{"output_type":"stream","name":"stdout","text":["train: ../train/images\n","val: ../valid/images\n","test: ../test/images\n","\n","nc: 1\n","names: ['trash']\n","\n","roboflow:\n","  workspace: mohamed-traore-2ekkp\n","  project: taco-trash-annotations-in-context\n","  version: 16\n","  license: CC BY 4.0\n","  url: https://universe.roboflow.com/mohamed-traore-2ekkp/taco-trash-annotations-in-context/dataset/16"]}],"source":["!cat /content/TACO_Data/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"VWufTcd6cwcX"},"source":["### 2-2) custom data에 대한 yaml 파일 만들기"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14289,"status":"ok","timestamp":1715314359795,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"cYuCZ43kcmAz","outputId":"cbc5d79b-2e05-43bd-9a37-aa2e0815b3c5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (6.0.1)\n"]}],"source":["# 파이썬에서 YAML 파일을 사용하기 위해 PyYAML 라이브러리 설치\n","!pip install PyYAML"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1715315306333,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"-d8jGue1cvpG","outputId":"e7981768-da07-402f-b6b2-6136683be212"},"outputs":[{"output_type":"stream","name":"stdout","text":["{'names': ['trash'], 'nc': 1, 'roboflow': {'license': 'CC BY 4.0', 'project': 'taco-trash-annotations-in-context', 'url': 'https://universe.roboflow.com/mohamed-traore-2ekkp/taco-trash-annotations-in-context/dataset/16', 'version': 16, 'workspace': 'mohamed-traore-2ekkp'}, 'test': '../test/images', 'train': '/content/TACO_Data/train.txt', 'val': '/content/TACO_Data/val.txt'}\n"]},{"output_type":"display_data","data":{"text/plain":["{'names': ['trash'],\n"," 'nc': 1,\n"," 'roboflow': {'license': 'CC BY 4.0',\n","  'project': 'taco-trash-annotations-in-context',\n","  'url': 'https://universe.roboflow.com/mohamed-traore-2ekkp/taco-trash-annotations-in-context/dataset/16',\n","  'version': 16,\n","  'workspace': 'mohamed-traore-2ekkp'},\n"," 'test': '../test/images',\n"," 'train': '/content/TACO_Data/train/',\n"," 'val': '/content/TACO_Data/val/'}"]},"metadata":{}}],"source":["# yaml 파일을 학습이 가능하도록 경로 설정.\n","# key-value 데이터인 dict 데이터타입으로 data['train'], data['val'], data['nc'], data['names'] 에 넣어주는데,\n","# 가장 중요한 부분은 데이터 경로 설정임.\n","\n","import yaml\n","# 디렉토리 정보, 클래스 이름(names), 클래스 수(nc) 지정하기\n","import yaml\n","with open('/content/TACO_Data/data.yaml') as f:\n","    data = yaml.full_load(f)\n","\n","print(data)\n","data['train'] = '/content/TACO_Data/train/'\n","data['val'] = '/content/TACO_Data/val/'\n","\n","# 데이터 경로와 클래스 정보를 저장하고 있는 딕셔너리 객체 data를 YOLOv8 학습에 필요한 새로운 이름으로 저장\n","with open('/content/TACO_Data/data.yaml', 'w') as f:\n","    yaml.dump(data, f)\n","\n","# Aquarium_Data.yaml 읽어서 화면에 출력\n","with open('/content/TACO_Data/data.yaml', 'r') as f:\n","  aquarium_yaml = yaml.safe_load(f)\n","  display(aquarium_yaml)"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1715315308229,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"f2zjrFqUdkzi","outputId":"d63448de-68b5-4329-a1ac-ba50d685556b"},"outputs":[{"output_type":"stream","name":"stdout","text":["names:\n","- trash\n","nc: 1\n","roboflow:\n","  license: CC BY 4.0\n","  project: taco-trash-annotations-in-context\n","  url: https://universe.roboflow.com/mohamed-traore-2ekkp/taco-trash-annotations-in-context/dataset/16\n","  version: 16\n","  workspace: mohamed-traore-2ekkp\n","test: ../test/images\n","train: /content/TACO_Data/train/\n","val: /content/TACO_Data/val/\n"]}],"source":["!cat /content/TACO_Data/data.yaml"]},{"cell_type":"markdown","metadata":{"id":"whvUm98aEm5_"},"source":["## **2. yolov8 사용을 위한 패키지 설치 및 가져오기**\n","- https://github.com/ultralytics/ultralytics"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"pBVEqPgPXLXc","executionInfo":{"status":"ok","timestamp":1715315309443,"user_tz":-540,"elapsed":1,"user":{"displayName":"가온새나","userId":"00832727552783796679"}}},"outputs":[],"source":["# PyTorch window 에 설치\n","#- https://pytorch.org/get-started/locally/\n","# !pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n","\n","# 위 실행해서 안되면 아래 명령 실행\n","#!conda install pytorch==2.2.2 torchvision==0.17.2 torchaudio==2.2.2 pytorch-cuda=12.1 -c pytorch -c nvidia"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":9124,"status":"ok","timestamp":1715315320445,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"8p1603VijJ_x"},"outputs":[],"source":["# 패키지 설치하기\n","!pip install -q ultralytics"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1715315320445,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"WnS0XLAcj1aO","outputId":"83abb3e4-1e6d-41e9-cff6-7f243d718901"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.11 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 30.5/78.2 GB disk)\n"]}],"source":["# 패키지 버전 확인하기\n","import ultralytics\n","\n","ultralytics.checks()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1715315320445,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"GgMdC7qnmMeW","outputId":"646698af-fc08-48d3-9f90-7160aa5399c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["2.2.1+cu121\n","Using device: cuda\n"]}],"source":["import torch\n","torch.cuda.get_device_name(0)\n","torch.cuda.is_available()\n","print(torch.__version__)\n","\n","# GPU가 사용 가능한지 확인하고, 사용 가능하면 CUDA를 사용하도록 설정\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"markdown","metadata":{"id":"u-U7UBFWFhlc"},"source":["## **3.모델 객체 선언하고 학습하기**\n","\n","### 1) 모델 객체 선언하기"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715315320445,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"Das7YGgqmSUL"},"outputs":[],"source":["# YOLO 라이브러리 가져오기\n","from ultralytics import YOLO   # ... code here\n","\n","# 'yolov8n-seg.pt' 모델 선언하기 - 사전학습된 YOLOv8n detection model 로드하기\n","model = YOLO('yolov8n-seg.pt')     # ... code here"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1715315320446,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"7X_3dSOFPQi3","outputId":"1cafbcda-7d29-4a51-d9ae-d59b12a55ad0"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'dict'> 80\n","{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"]}],"source":["# Yolov8은 MS COCO 데이터 사전학습되어있어 MS COCO Dataset에 정의된 클래스 개수오 ㅏ종류 확인할 수 있음(0~79)\n","print(type(model.names), len(model.names))\n","\n","print(model.names)"]},{"cell_type":"markdown","metadata":{"id":"Ux1yjJYu88Ro"},"source":["### 2) 모델 학습하기 (자신의 만든 yaml파일 지정)"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":632},"executionInfo":{"elapsed":563,"status":"error","timestamp":1715315321004,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"eeF3uPiAYyBD","outputId":"fe2ea366-8e56-4746-ccd5-485329f048de"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.11 🚀 Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=/content/TACO_Data/data.yaml, epochs=50, time=None, patience=30, batch=32, imgsz=416, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/segment/train4\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Dataset '/content/TACO_Data/data.yaml' error ❌ \nDataset '/content/TACO_Data/data.yaml' images not found ⚠️, missing path '/content/TACO_Data/val'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.yaml'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    516\u001b[0m             }:\n\u001b[0;32m--> 517\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_det_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"yaml_file\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/data/utils.py\u001b[0m in \u001b[0;36mcheck_det_dataset\u001b[0;34m(dataset, autodownload)\u001b[0m\n\u001b[1;32m    328\u001b[0m                 \u001b[0mm\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"\\nNote dataset download directory is '{DATASETS_DIR}'. You can update this in '{SETTINGS_YAML}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: \nDataset '/content/TACO_Data/data.yaml' images not found ⚠️, missing path '/content/TACO_Data/val'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.yaml'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-81ae0b26d028>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 모델 학습하기 (자신의 만든 yaml파일 지정)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/TACO_Data/data.yaml'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimgsz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m416\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, trainer, **kwargs)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_smart_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"trainer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"resume\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# manually set model only if not resuming\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mckpt\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/models/yolo/segment/train.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0moverrides\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0moverrides\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"task\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"segment\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, cfg, overrides, _callbacks)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;31m# Model and Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_model_file_from_stem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# add suffix, i.e. yolov8n -> yolov8n.pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ultralytics/engine/trainer.py\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"yaml_file\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# for validating 'yolo train data=url.zip' usage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0memojis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Dataset '{clean_url(self.args.data)}' error ❌ {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Dataset '/content/TACO_Data/data.yaml' error ❌ \nDataset '/content/TACO_Data/data.yaml' images not found ⚠️, missing path '/content/TACO_Data/val'\nNote dataset download directory is '/content/datasets'. You can update this in '/root/.config/Ultralytics/settings.yaml'"]}],"source":["# 모델 학습하기 (자신의 만든 yaml파일 지정)\n","model.train(data='/content/TACO_Data/data.yaml', epochs=50, patience=30, batch=32, imgsz=416)"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1715315239473,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"rU4hUb6aRMu5","outputId":"c5c1388b-5b55-43f5-b897-aae63e545c7e"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'dict'> 80\n","{0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n"]}],"source":["# 커스텀 데이터로 학습하였기 때문에 클래수 수의 변경됨을 확인할 수 있음\n","print(type(model.names), len(model.names))\n","\n","print(model.names)"]},{"cell_type":"markdown","metadata":{"id":"-XTkv6lRnYq6"},"source":["### ▲ train 과정중에 loss, accuracy 등의 graph 데이터는 runs/detect/train/ 에 있는 results.csv 와 results.png 통해서 확인가능함"]},{"cell_type":"markdown","metadata":{"id":"PGvvaF60Fp2U"},"source":["### 3) 테스트 이미지 데이터 생성 및 확인"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1715314360993,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"QknTB5poU_3-"},"outputs":[],"source":["# 테스트 이미지\n","from glob import glob\n","\n","test_image_list = glob('/content/TACO_Data/test/images/*')\n","test_image_list.sort()\n","\n","for i in range(len(test_image_list)):\n","    print('i = ',i, test_image_list[i])"]},{"cell_type":"markdown","metadata":{"id":"cKdlujLuFxui"},"source":["## **4.객체 검출 (Inference or predict)**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1715314360993,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"Iy_75ZcSU_4E"},"outputs":[],"source":["results =  model.predict(source=test_image_list, save=True)    # ... code here"]},{"cell_type":"markdown","metadata":{"id":"fZBn8ChCgXql"},"source":["## **5. 결과 확인하기**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1715314360993,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"CWuCAASSfy66"},"outputs":[],"source":["print(type(results), len(results))"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1715314360993,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"_TFeaA3CkfFX"},"outputs":[],"source":["import numpy as np\n","\n","for result in results:\n","    uniq, cnt = np.unique(result.boxes.cls.cpu().numpy(), return_counts=True)  # Torch.Tensor -> numpy\n","    uniq_cnt_dict = dict(zip(uniq, cnt))\n","\n","    print('\\n{class num : counts} =', uniq_cnt_dict,'\\n')\n","\n","    for i, c in enumerate(result.boxes.cls):\n","        class_id = int(c)\n","        class_name = result.names[class_id]\n","        confidence_score = result.boxes.conf[i]  # 예측 확률\n","        print(f'class num: {class_id:>2} , class name: {class_name :<13}, confidence: {confidence_score:.2f}')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dqHEC1tU-gdR","executionInfo":{"status":"aborted","timestamp":1715314360993,"user_tz":-540,"elapsed":5,"user":{"displayName":"가온새나","userId":"00832727552783796679"}}},"outputs":[],"source":["# 테스트 이미지 모두 예측 결과 이미지로 나타내기\n","from PIL import Image\n","from IPython.display import display\n","import os\n","\n","# 이미지가 저장된 폴더 경로\n","image_dir = \"runs/segment/predict\"    # ... code here\n","\n","# 폴더 내의 모든 파일을 순회\n","for file_name in os.listdir(image_dir):\n","    file_path = os.path.join(image_dir, file_name)\n","    # 파일 확장자가 .jpg인 경우에만 처리\n","    if file_path.endswith('.jpg'):\n","        with Image.open(file_path) as img:\n","            display(img)"]},{"cell_type":"markdown","metadata":{"id":"99Ex5nU5F55F"},"source":["## **6. 결과 다운로드**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":5,"status":"aborted","timestamp":1715314360993,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"xHOOYeLAHSb_"},"outputs":[],"source":["import glob\n","\n","detetced_image_list = glob.glob(('/content/runs/segment/predict/*'))\n","detected_image_nums = len(detetced_image_list)\n","\n","print(detected_image_nums)\n","print(detetced_image_list)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":6,"status":"aborted","timestamp":1715314360994,"user":{"displayName":"가온새나","userId":"00832727552783796679"},"user_tz":-540},"id":"wYFPNzfMSOyt"},"outputs":[],"source":["# 다운로드를 위한 inference image 압축\n","\n","import zipfile\n","import os\n","\n","if not os.path.exists('/content/detected_result/'):\n","    os.mkdir('/content/detected_result/')\n","    print('detected_result dir is created !!!')\n","\n","with zipfile.ZipFile('/content/detected_result/detected_images.zip', 'w') as detected_images:\n","\n","    for idx in range(detected_image_nums):\n","        detected_images.write(detetced_image_list[idx])"]},{"cell_type":"markdown","metadata":{"id":"na1BHNDGBxHS"},"source":["## **CVAT** 을 사용하여 Object Detection을 위한 사용자 데이터셋 정의하기\n","- CVAT : nnotation Platform\n","- https://www.cvat.ai/ : Open Data\n"]},{"cell_type":"markdown","metadata":{"id":"_hdrua1HSIza"},"source":["## **7.학습된 모델 내보내기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9qSn1gCSWxS"},"outputs":[],"source":["# 모델을 내보내기\n","model.save('trained_yolov8n.pt')\n","\n","# 내보낸 모델을 로드하여 사용\n","model = YOLO('trained_yolov8n.pt')"]},{"cell_type":"markdown","source":["## 8. 테스트 이미지로 테스트 또는 웹캠 이용해 실시간 추론하기"],"metadata":{"id":"5A90pOnjSe_8"}},{"cell_type":"code","source":["# 이미지에 대한 추론 수행\n","results = model('test_image.jpg')\n","print(results.pandas().xyxy[0])  # 추론 결과 출력"],"metadata":{"id":"rxn1pNdNSbIO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 학습된 모델을 로드합니다.\n","model = YOLO('trained_yolov8n.pt')\n","\n","# 웹캠 초기화\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # 모델을 사용하여 프레임에서 객체 감지\n","    results = model(frame)\n","\n","    # 결과를 프레임에 그리기\n","    annotated_frame = results.render()[0]\n","\n","    # 화면에 표시\n","    cv2.imshow(\"YOLOv8 Real-Time Detection\", annotated_frame)\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","cap.release()\n","cv2.destroyAllWindows()"],"metadata":{"id":"xiXvfIfnSlMS"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1-q_4pm_xPIwZ0z7uojomtfAkkAqslPHS","timestamp":1715298987366}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":0}